{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%%configure\n{\n   \"--datalake-formats\": \"iceberg\",\n    \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.catalog.glue_catalog.warehouse=file:///tmp/spark-warehouse --conf spark.sql.defaultCatalog=glue_catalog\"\n}  ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nThe following configurations have been updated: {'--datalake-formats': 'iceberg', '--conf': 'spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.catalog.glue_catalog.warehouse=file:///tmp/spark-warehouse --conf spark.sql.defaultCatalog=glue_catalog'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nfrom datetime import datetime\nimport pandas as pd\nfrom pyspark.sql.functions import to_timestamp\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: d924d1ec-290a-4346-9ed3-0f8bda130194\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\n--datalake-formats iceberg\n--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.catalog.glue_catalog.warehouse=file:///tmp/spark-warehouse --conf spark.sql.defaultCatalog=glue_catalog\nWaiting for session d924d1ec-290a-4346-9ed3-0f8bda130194 to get into ready status...\nSession d924d1ec-290a-4346-9ed3-0f8bda130194 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime\nimport pandas as pd\nfrom pyspark.sql.functions import to_timestamp, to_date, col, when, lit\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import LongType",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# Delete rows where ID is not int\n# New line characters to be removed, like /n\n# Remove empty columns and almost empty",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "### Load data from bronze layer",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dyf_sunbird_tweets_bronze = glueContext.create_dynamic_frame.from_catalog(database=\"tgsn_bronze\", table_name=\"sunbird_x_tweets\", transformation_ctx=\"dyf_sunbird_bronze\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 47,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "dyf_sunbird_users_bronze = glueContext.create_dynamic_frame.from_catalog(database=\"tgsn_bronze\", table_name=\"sunbird_x_users\", transformation_ctx=\"dyf_sunbird_users_bronze\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 48,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Converto from dynamic dataframe to spark dataframe",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze = dyf_sunbird_tweets_bronze.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 49,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_users_bronze = dyf_sunbird_users_bronze.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 50,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_users_bronze.columns",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 51,
			"outputs": [
				{
					"name": "stdout",
					"text": "['id', 'name', 'username', 'created_at', 'protected', 'withheld', 'location', 'url', 'description', 'verified', 'verified_type', 'entities', 'profile_image_url', 'public_metrics', 'pinned_tweet_id', 'pinned_tweet_text', 'most_recent_tweet_id', 'most_recent_tweet_text', 'collection_date']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Drop all rows where the tweet_id is not an integer",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze = df_sunbird_tweets_bronze.withColumn(\n    'tweet_id_validation',F.col(\"tweet_id\").cast(LongType()).isNotNull()\n    ).filter(\n        \"tweet_id_validation=='true'\"\n            ).drop(\"tweet_id_validation\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 52,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_users_bronze = df_sunbird_users_bronze.withColumn(\n    'most_recent_tweet_id_validation',F.col(\"most_recent_tweet_id\").cast(LongType()).isNotNull()\n    ).filter(\n        \"most_recent_tweet_id_validation=='true' or most_recent_tweet_id is null or most_recent_tweet_id == ''\"\n            ).drop(\"most_recent_tweet_id_validation\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 53,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Check if there are tweet_ids that are not int",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze.select(\n  \"tweet_id\",\n  F.col(\"tweet_id\").cast(LongType()).isNotNull().alias(\"Value\")\n).where(\"Value =='false'\").show(20, False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 54,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+-----+\n|tweet_id|Value|\n+--------+-----+\n+--------+-----+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_users_bronze.select(\n  \"most_recent_tweet_id\",\n  F.col(\"most_recent_tweet_id\").cast(LongType()).isNotNull().alias(\"Value\")\n).where(\"Value =='false' and most_recent_tweet_id is not null and most_recent_tweet_id != ''\").show(20, False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-----+\n|most_recent_tweet_id|Value|\n+--------------------+-----+\n+--------------------+-----+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Remove all '\\n' ",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze = df_sunbird_tweets_bronze.withColumn('tweet_content', F.regexp_replace('tweet_content', '\\n', ''))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 56,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_users_bronze = df_sunbird_users_bronze.withColumn(\n    'description', F.regexp_replace('description', '\\n', '')).withColumn(\n    'pinned_tweet_text', F.regexp_replace('pinned_tweet_text', '\\n', '')).withColumn(\n    'most_recent_tweet_text', F.regexp_replace('most_recent_tweet_text', '\\n', ''))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 57,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze.where(\"tweet_content like '%\\n%'\").select(df_sunbird_tweets_bronze.columns[8:12]).show(5, False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 58,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------------+----------------------+------------------------------+----------------------------+\n|tweet_content|edit_history_tweet_ids|edit_controls_is_edit_eligible|edit_controls_editable_until|\n+-------------+----------------------+------------------------------+----------------------------+\n+-------------+----------------------+------------------------------+----------------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Check if the edit_history_tweet_ids has anything that are not tweet_ids",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df_sunbird_tweets_bronze.withColumn(\n    'edit_history_tweet_ids_noComma', F.regexp_replace('edit_history_tweet_ids', ',', '')).select(\n      \"edit_history_tweet_ids_noComma\",\n      F.col(\"edit_history_tweet_ids_noComma\").cast(LongType()).isNotNull().alias(\"Value\")\n    ).filter(F.col(\"edit_history_tweet_ids_noComma\").rlike('\\D+')).show(20, False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 59,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------------------------------+-----+\n|edit_history_tweet_ids_noComma|Value|\n+------------------------------+-----+\n+------------------------------+-----+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "No lines, all rows have tweet_ids in edit_history_tweet_ids",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "markdown",
			"source": "### Replace empty values '' for None",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "for column in df_sunbird_tweets_bronze.columns:\n    df_sunbird_tweets_bronze = \\\n    df_sunbird_tweets_bronze.withColumn(column, \\\n                                        when(df_sunbird_tweets_bronze[f'{column}']=='' ,None) \\\n                                        .otherwise(df_sunbird_tweets_bronze[f'{column}']))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 60,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "for column in df_sunbird_users_bronze.columns:\n    df_sunbird_users_bronze = \\\n    df_sunbird_users_bronze.withColumn(column, \\\n                                        when(df_sunbird_users_bronze[f'{column}']=='' ,None) \\\n                                        .otherwise(df_sunbird_users_bronze[f'{column}']))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 61,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Check empty columns and almost empty columns",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "empty_col = []\nalmost_empty_col = []\nthreshold = 0.1 # threshold to use to define almost empty columns\n\ntotal_count = df_sunbird_tweets_bronze.count()\nfor column in df_sunbird_tweets_bronze.columns:\n    cnt = df_sunbird_tweets_bronze.where(df_sunbird_tweets_bronze[f'{column}'].isNotNull()).count()\n    if cnt == 0:\n        empty_col.append(column)\n        df_sunbird_tweets_bronze = df_sunbird_tweets_bronze.drop(column)\n\n    elif cnt/total_count < threshold:\n        almost_empty_col.append(column)\n        df_sunbird_tweets_bronze = df_sunbird_tweets_bronze.drop(column)\n\nprint(f'Empty columns: {empty_col}')\nprint(f'-------------')\nprint(f'Almost empty columns: {almost_empty_col}')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 62,
			"outputs": [
				{
					"name": "stdout",
					"text": "Empty columns: ['poll_end', 'poll_ids', 'source_app', 'place_contained_within', 'place_country', 'place_country_code', 'place_full_name', 'place_name', 'place_type']\n-------------\nAlmost empty columns: ['note_tweet_text', 'poll_duration_minutes', 'poll_options', 'poll_voting_status', 'geo_place_id', 'geo_coordinates', 'withheld_copyright', 'withheld_country_codes', 'place_id']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "empty_col = []\nalmost_empty_col = []\nthreshold = 0.1 # threshold to use to define almost empty columns\n\ntotal_count = df_sunbird_users_bronze.count()\nfor column in df_sunbird_users_bronze.columns:\n    cnt = df_sunbird_users_bronze.where(df_sunbird_users_bronze[f'{column}'].isNotNull()).count()\n    if cnt == 0:\n        empty_col.append(column)\n        df_sunbird_users_bronze = df_sunbird_users_bronze.drop(column)\n\n    elif cnt/total_count < threshold:\n        almost_empty_col.append(column)\n        df_sunbird_users_bronze = df_sunbird_users_bronze.drop(column)\n\nprint(f'Empty columns: {empty_col}')\nprint(f'-------------')\nprint(f'Almost empty columns: {almost_empty_col}')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 63,
			"outputs": [
				{
					"name": "stdout",
					"text": "Empty columns: []\n-------------\nAlmost empty columns: []\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Save cleaned data into Silver",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "additional_options = {}\n# Create or replace table\ndf_sunbird_tweets_bronze.writeTo(\"glue_catalog.tgsn_silver.sunbird_x_tweets\") \\\n        .tableProperty(\"format-version\", \"2\") \\\n        .tableProperty(\"location\", \"s3://tgsn-silver-bucket/sunbird/x/tweets/tgsn_silver/sunbird_x_tweets\") \\\n        .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n        .options(**additional_options) \\\n        .partitionedBy(\"collection_date\") \\\n.createOrReplace()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 66,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "additional_options = {}\n# Create or replace table\ndf_sunbird_users_bronze.writeTo(\"glue_catalog.tgsn_silver.sunbird_x_users\") \\\n        .tableProperty(\"format-version\", \"2\") \\\n        .tableProperty(\"location\", \"s3://tgsn-silver-bucket/sunbird/x/users/tgsn_silver/sunbird_x_users\") \\\n        .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n        .options(**additional_options) \\\n        .partitionedBy(\"collection_date\") \\\n.createOrReplace()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 65,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}